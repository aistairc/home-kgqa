# HOME-KGQA

A benchmark dataset designed to evaluate KGQA (Knowledge Graph Question Answering) models in daily activity environments


## Quick Start

If you want to use the dataset, you can find them in the following directories:

- **QA Datasets**: `dataset/qa/` - Contains train/test datasets for question answering ([details in README](dataset/qa/README.md))
- **Prompt Datasets**: `dataset/prompt/` - Contains prompt datasets for instruction tuning ([details in README](dataset/prompt/README.md))
- **KG Datasets**: `dataset/kg/` - Contains episodic KG datasets, which are the target KGs for KGQA ([details in README](dataset/kg/README.md))


> **Note**: If you only want to use the pre-generated datasets, you do not need to run any of the following sections. The sections below are only for rebuilding or augmenting the datasets.

## Setup

0. **Install uv (if not installed)**:
   - macOS/Linux:
   ```bash
   curl -Ls https://astral.sh/uv/install.sh | sh
   ```
   - Homebrew (macOS):
   ```bash
   brew install uv
   ```

1. **Install dependencies**:
   ```bash
   uv sync
   ```

2. **Configure OpenAI API key**:
   - Edit `config.json` and replace `your-openai-api-key-here` with your OpenAI API key

## Usage

### Generate Questions
```bash
# Generate 150 questions for each answer type
python generate_questions.py --loop 150

```

### Paraphrase Questions
```bash
# Paraphrase questions generated by the above command
python paraphrase_questions.py --loop 150
```

### Split Dataset
```bash
# Split all paraphrased questions into train and test sets
python split_dataset.py --loop 150
```

### Merge Questions
```bash
# Merge all test files for loop=10
python merge_generated_questions.py --loop 150 --type test

# Merge all train files for loop=10
python merge_generated_questions.py --loop 150 --type train
```

## Advanced Usage

### Generate Episodic Knowledge Graph

**Note**: This step requires downloading the VHAKG dataset first and is only needed for advanced users.

1. **Download and setup VHAKG dataset**:
   ```bash
   cd dataset/
   wget https://zenodo.org/records/11438499/files/vhakg_event.tar.gz?download=1 -O vhakg_event.tar.gz
   wget https://zenodo.org/record/11438499/files/vhakg_video_base64.tar.gz?download=1 -O vhakg_video_base64.tar.gz
   tar -zxvf vhakg_event.tar.gz
   tar -zxvf vhakg_video_base64.tar.gz
   ```

2. **Generate episodic knowledge graph**:
   ```bash
   python generate_episodic_kg.py
   ```

## License

- **Datasets**: [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)
- **Code**: [MIT License](https://opensource.org/licenses/MIT)
